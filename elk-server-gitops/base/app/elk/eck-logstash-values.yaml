---
# Default values for eck-logstash.
# This is a YAML-formatted file.

# Overridable names of the Logstash resource.
# By default, this is the Release name set for the chart,
# followed by 'eck-logstash'.
#
# nameOverride will override the name of the Chart with the name set here,
# so nameOverride: quickstart, would convert to '{{ Release.name }}-quickstart'
#
nameOverride: "elkcorp"
#
# fullnameOverride will override both the release name, and the chart name,
# and will name the Logstash resource exactly as specified.
#
#fullnameOverride: ""
#

# Version of Logstash.
#
version: 8.17.0

# Logstash Docker image to deploy
#
# image:

# Used to check access from the current resource to a resource (for ex. a remote Elasticsearch cluster) in a different namespace.
# Can only be used if ECK is enforcing RBAC on references.
#
# serviceAccountName: ""

# Labels that will be applied to Logstash.
#
labels: {}

# Annotations that will be applied to Logstash.
#
annotations: {}

# Number of revisions to retain to allow rollback in the underlying StatefulSets.
# By default, if not set, Kubernetes sets 10.
#
# revisionHistoryLimit: 2

# Controlling the number of pods.
# ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-logstash-scaling-logstash.html
#
count: 4

# The logstash configuration, the ECK equivalent to logstash.yml
#
# NOTE: The `config` and `configRef` fields are mutually exclusive. Only one of them should be defined at a time,
# as using both may cause conflicts.
# ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-logstash-configuration.html#k8s-logstash-configuring-logstash
#
config:
  log.level: info #debug  # Enable detailed logs for troubleshooting
  api.http.host: "0.0.0.0"       # Allows the Logstash monitoring API to be accessible
  api.http.port: 9600
  #api.ssl.enabled: false
  queue.type: persisted      # Store events on disk to prevent data loss in case of crashes
  pipeline.workers: 4       # Number of threads to process events
  pipeline.batch.size: 500   # Number of events processed per batch
  pipeline.batch.delay: 5   # Time (ms) to wait before processing events
  #log.format: json  # Makes logs easier to parse
  

# Reference a configuration in a Secret.
# ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-logstash-configuration.html#k8s-logstash-configuring-logstash
#
# configRef:
#   secretName: ''

# Set podTemplate to customize the pod used by Logstash
# ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-customize-pods.html
#
podTemplate:
   spec:
     affinity:
       nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
           nodeSelectorTerms:
           - matchExpressions:
             - key: eck-role
               operator: In
               values:
               - logstash
     tolerations:
     - key: "eck-role"
       operator: "Equal"
       value: "logstash"
       effect: "NoSchedule"
     containers:
     - name: logstash
       resources:
          limits:
             cpu: 2
             memory: 8Gi
          requests:
             cpu: 1
             memory: 4Gi
#       volumeMounts:
#        - name: ca-certs
#          mountPath: /etc/certs
#          readOnly: true
#     volumes:
#     - name: ca-certs
#       secret:
#         secretName: logstash-certs-full-chain
#         optional: false

# Settings for configuring stack monitoring.
# ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-stack-monitoring.html
#
monitoring: {}
  # metrics:
  #   elasticsearchRefs:
  #   - name: monitoring
  #     namespace: observability 
  # logs:
  #   elasticsearchRefs:
  #   - name: monitoring
  #     namespace: observability

# The Logstash pipelines, the ECK equivalent to pipelines.yml
#
# NOTE: The `pipelines` and `pipelinesRef` fields are mutually exclusive. Only one of them should be defined at a time,
# as using both may cause conflicts.
# ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-logstash-configuration.html#k8s-logstash-pipelines
# 
pipelines:
- pipeline.id: beats_logs
  config.string: |
    input {
      beats {
        port => 5044
      }
    }

    filter {
      if [message] and [message] =~ /^\s*{/ {
        json {
          source => "message"
          target => "raw_event"
          skip_on_invalid_json => true
          tag_on_failure => ["invalid_json_message"]
        }
      } else if [Body] {
        json {
          source => "Body"
          target => "raw_event"
          skip_on_invalid_json => true
          tag_on_failure => ["invalid_json_body"]
        }
      } else {
        mutate {
          add_tag => ["no_json_detected"]
        }
      }

      if [raw_event][Attributes] {
        mutate {
          add_field => { "ecs_compatible" => "true" }
          merge => { "event" => "[raw_event][Attributes]" }
        }

        mutate {
          rename => {
            "Timestamp" => "@timestamp"
            "SeverityText" => "log.level"
            "Body" => "message"
            "TraceId" => "trace.id"
            "SpanId" => "span.id"
            "Resource" => "[host]"
            "Attributes" => "[event]"
            "[event][event.provider]" => "[service.name]"
            "[event][event.module]" => "[event.module]"
            "[event][event.category]" => "[event.category]"
            "[event][event.type]" => "[event.type]"
            "[event][event.kind]" => "[event.kind]"
            "[event][event.start]" => "[event.start]"
            "[event][labels.environment]" => "[labels.environment]"
            "[event][http.request.method]" => "[http.request.method]"
            "[event][http.response.status_code]" => "[http.response.status_code]"
            "[event][client.address]" => "[client.ip]"
            "[event][client.port]" => "[client.port]"
            "[event][url.full]" => "[url.full]"
            "[event][url.scheme]" => "[url.scheme]"
            "[event][url.path]" => "[url.path]"
            "[event][url.query]" => "[url.query]"
          }
        }
      }

      if ![raw_event] and [attr.message] {
        mutate {
          rename => {
            "attr.message" => "message"
            "timestamp" => "@timestamp"
            "log_level" => "log.level"
            "trace_id" => "trace.id"
            "span_id" => "span.id"
            "resource.service.name" => "[service][name]"
            "resource.deployment.environment" => "[labels.environment]"
          }
          add_field => {
            "ecs_compatible" => "true"
          }
        }
      }

      prune {
        interpolate => true
        whitelist_names => [".+"]
        blacklist_values => ["null", ""]
      }

     if ![@metadata][app] {
        if [service][name] {
          mutate { add_field => { "[@metadata][app]" => "%{[service][name]}" } }
        } else if [resource][service.name] {
          mutate { add_field => { "[@metadata][app]" => "%{[resource][service.name]}" } }
        } else if [resource.service.name] {
          mutate { add_field => { "[@metadata][app]" => "%{[resource.service.name]}" } }
        } else if [event][provider] {
          mutate { add_field => { "[@metadata][app]" => "%{[event][provider]}" } }
        } else if [Attributes][event.provider] {
          mutate { add_field => { "[@metadata][app]" => "%{[Attributes][event.provider]}" } }
        } else if ![@metadata][app] and [resource][app] {
          mutate { add_field => { "[@metadata][app]" => "%{[resource][app]}" } }
        } else if ![@metadata][app] and [resource][project][name] {
          mutate { add_field => { "[@metadata][app]" => "%{[resource][project][name]}" } }
        } else if [fields][app] {
          mutate { add_field => { "[@metadata][app]" => "%{[fields][app]}" } }
        } else {
          mutate {
            add_field => { "[@metadata][app]" => "unknown" }
            add_tag => ["fallback_app"]
          }
        }
      }

      if ![@metadata][env] {
        if [labels][environment] {
          mutate { add_field => { "[@metadata][env]" => "%{[labels][environment]}" } }
        } else if [event][labels.environment] {
          mutate { add_field => { "[@metadata][env]" => "%{[event][labels.environment]}" } }
        } else if [Attributes][labels.environment] {
          mutate { add_field => { "[@metadata][env]" => "%{[Attributes][labels.environment]}" } }
        } else if [resource][deployment.environment] {
          mutate { add_field => { "[@metadata][env]" => "%{[resource][deployment.environment]}" } }
        } else if [resource.deployment.environment] {
          mutate { add_field => { "[@metadata][env]" => "%{[resource.deployment.environment]}" } }
        } else  if ![@metadata][env] and [resource][env] {
          mutate { add_field => { "[@metadata][env]" => "%{[resource][env]}" } }
        } else if [fields][env] {
          mutate { add_field => { "[@metadata][env]" => "%{[fields][env]}" } }
        } else {
          mutate { add_field => { "[@metadata][env]" => "default" } }
        }
      }

      mutate {
        lowercase => [ "[@metadata][app]", "[@metadata][env]" ]
      }
      mutate {
        add_field => {
          "[@metadata][target_index]" => "logs-%{[@metadata][app]}-%{[@metadata][env]}"
        }
      }

      if "invalid_json_message" in [tags] or "invalid_json_body" in [tags] or "fallback_app" in [tags] {
        mutate {
          add_tag => ["pipeline_debug"]
        }
      }

      fingerprint {
        source => "message"
        target => "[@metadata][fingerprint]"
        method => "SHA256"
      }

      mutate {
        remove_field => ["raw_event"]
      }
    }

    output {
      elasticsearch {
        hosts => ["http://elastic-elkcorp-es-http:9200"]
        user => "${ELASTIC_ELKCORP_ES_USER}"
        password => "${ELASTIC_ELKCORP_ES_PASSWORD}"
        action => "create"
        data_stream => false
        index => "%{[@metadata][target_index]}-%{+YYYY.MM.dd}"
        ssl_enabled => false
      }
    }

- pipeline.id: tcp_logs
  config.string: |
    input {
      tcp {
        port => 5080
        codec => json_lines {
          target => "raw_input"
          ecs_compatibility => "v8"
          decode_size_limit_bytes => 104857600
        }
      }
    }

    filter {
      if ![raw_input] {
        if [message] { mutate { add_field => { "[raw_input][message]" => "%{[message]}" } } }
        if [body] { mutate { add_field => { "[raw_input][body]" => "%{[body]}" } } }
      }

      mutate { add_field => { "[event][original]" => "%{[raw_input]}" }}

      ruby {
        code => '
          require "json"

          v = event.get("[event][original]")
          begin
            if v.is_a?(Hash) || v.is_a?(Array)
              event.set("[event][original]", JSON.generate(v))
            elsif v.is_a?(String)
              parsed = JSON.parse(v) rescue nil
              event.set("[event][original]", JSON.generate(parsed)) if parsed
            end
          rescue; end

          ri = event.get("raw_input")
          if ri.is_a?(Hash)
            event.set("raw_event", ri)
            event.set("[event][original]", JSON.generate(ri)) rescue nil

            inner = ri["body"] || ri["message"]
            if inner.is_a?(String)
              s = inner.strip
              if s.start_with?("{","[")
                begin
                  parsed = JSON.parse(s)
                  if parsed.is_a?(Hash)
                    if parsed["attributes"] ||
                      parsed.dig("resource","telemetry","sdk","name") ||
                      (parsed["trace_id"] && parsed["span_id"])
                      event.set("raw_event", parsed)
                      tags = (event.get("tags") || []) << "opentelemetry_schema"
                      event.set("tags", tags.uniq)
                      event.set("ecs_compatible", true)
                      event.set("[ecs][version]", "8.11.0")
                    else
                      event.set("[raw_event][body]", JSON.generate(parsed))
                    end
                  elsif parsed.is_a?(Array)
                    event.set("[raw_event][body]", JSON.generate(parsed))
                  end
                rescue; end
              else
                begin
                  jpos = s.index("{") || s.index("[")
                  if jpos
                    candidate = s[jpos..-1]
                    parsed = JSON.parse(candidate)
                    if parsed.is_a?(Hash)
                      if parsed["attributes"] ||
                         parsed.dig("resource","telemetry","sdk","name") ||
                         (parsed["trace_id"] && parsed["span_id"]) ||
                         parsed.key?("severity_text") || parsed.key?("resource") || parsed.key?("attributes") || parsed.key?("timestamp")
                        event.set("raw_event", parsed)
                        tags = (event.get("tags") || []) << "opentelemetry_schema" << "extracted_embedded_json"
                        event.set("tags", tags.uniq)
                        event.set("ecs_compatible", true)
                        event.set("[ecs][version]", "8.11.0")
                      else
                        event.set("[raw_event][body]", JSON.generate(parsed))
                      end
                    elsif parsed.is_a?(Array)
                      event.set("[raw_event][body]", JSON.generate(parsed))
                    else
                      event.set("[raw_event][body]", inner)
                    end
                  else
                    event.set("[raw_event][body]", inner)
                  end
                rescue
                  event.set("[raw_event][body]", inner)
                end
              end
            end
          end
        '
      }

      ruby {
        code => '
          require "json"
          b = event.get("[raw_event][body]")
          if b.is_a?(Hash) || b.is_a?(Array)
            event.set("[raw_event][body]", JSON.generate(b))
          end
        '
      }

      if ([raw_input][attributes] or
          [raw_input][resource][telemetry][sdk][name] or
          [raw_input]["resource.telemetry.sdk.name"] or
          ([raw_input][trace_id] and [raw_input][span_id])) {
        mutate {
          copy    => { "[raw_input]" => "[raw_event]" }
          add_tag => ["opentelemetry_schema"]
          add_field => { "ecs_compatible" => "true" "[ecs][version]" => "8.11.0" }
        }
      }

      if ![raw_event] {
        if (
            ([raw_input][body] and [raw_input][body] =~ /^\s*{.*"attributes":.*}\s*$/) or
            ([raw_input][body] and [raw_input][body] =~ /^\s*{.*"resource\.telemetry\.sdk\.name":.*}\s*$/) or
            ([event][original] and [event][original] =~ /^\s*{.*"attributes":.*}\s*$/) or
            ([event][original] and [event][original] =~ /^\s*{.*"resource\.telemetry\.sdk\.name":.*}\s*$/)
        ) {
          mutate { add_tag => ["possible_opentelemetry_schema"] }

          if [raw_input][body] {
            json { source => "[raw_input][body]" target => "raw_event" skip_on_invalid_json => true tag_on_failure => ["invalid_parse_json_otel_body"] }
          } else if [event][original] {
            json { source => "[event][original]" target => "raw_event" skip_on_invalid_json => true tag_on_failure => ["invalid_parse_json_otel_original"] }
          }

          if ([raw_event][attributes] or
              [raw_event][resource][telemetry][sdk][name] or
              [raw_event]["resource.telemetry.sdk.name"] or
              ([raw_event][trace_id] and [raw_event][span_id])) {
            mutate { add_tag    => ["opentelemetry_schema"] remove_tag => ["possible_opentelemetry_schema"] add_field  => { "ecs_compatible" => "true" "[ecs][version]" => "8.11.0" } }
          } else {
            mutate { add_tag    => ["non_opentelemetry_schema"] remove_tag => ["possible_opentelemetry_schema"] }
          }
        } else {
          mutate { add_tag => ["non_opentelemetry_schema"] }
        }

        if !("opentelemetry_schema" in [tags]) {
          if (
              ([raw_input][body]    and [raw_input][body]    =~ /^\s*{/) or
              ([raw_input][message] and [raw_input][message] =~ /^\s*{/) or
              ([event][original]    and [event][original]    =~ /^\s*{/)
          ) {
            mutate { add_tag => ["possible_generic_json"] }

          if [raw_input][body] {
              json { source => "[raw_input][body]" target => "raw_event" skip_on_invalid_json => true tag_on_failure => ["invalid_parse_json_generic_body"] }
            } else if [raw_input][message] {
              json { source => "[raw_input][message]" target => "raw_event" skip_on_invalid_json => true tag_on_failure => ["invalid_parse_json_generic_message"] }
            } else if [event][original] {
              json { source => "[event][original]" target => "raw_event" skip_on_invalid_json => true tag_on_failure => ["invalid_parse_json_generic_original"] }
            }

            if [raw_event] {
              mutate { add_tag => ["generic_json_schema"] remove_tag => ["possible_generic_json"] add_field  => { "ecs_compatible" => "false" } }
            } else {
              mutate { add_tag => ["non_generic_json_schema"] remove_tag => ["possible_generic_json"] }
            }
          } else {
            mutate { add_tag => ["no_json_detected"] }
          }
        }
      }

      if [raw_event] and !("opentelemetry_schema" in [tags]) and !("generic_json_schema" in [tags]) {
        mutate {
          add_tag   => ["generic_json_schema"]
          add_field => { "ecs_compatible" => "false" }
        }
      }

      ruby {
        code => '
          begin
            t = event.get("[raw_event][time_unix_nano]") || event.get("[raw_event][timeUnixNano]")
            if t
              n = t.to_s
              if n =~ /^\d+$/
                sec  = (n.length > 9) ? n[0..-10].to_i : 0
                nsec = (n.length > 9) ? n[-9..-1].to_i : n.to_i
                ts = LogStash::Timestamp.new(Time.at(sec, nsec, :nsec).utc)
                event.set("@timestamp", ts)
                tags = (event.get("tags") || []) << "ts_set"
                event.set("tags", tags.uniq)
              end
            end
          rescue => e
            tags = (event.get("tags") || []) << "date_parse_failed_time_unix_nano"
            event.set("tags", tags.uniq)
          end
        '
      }

      ruby {
        code => '
          unless (event.get("tags") || []).include?("ts_set")
            i = event.get("[raw_event][instant]")
            if i.is_a?(Hash) && (i["epochSecond"] || i[:epochSecond])
              sec  = (i["epochSecond"] || i[:epochSecond]).to_i
              nsec = (i["nanoOfSecond"] || i[:nanoOfSecond] || 0).to_i
              event.set("@timestamp", LogStash::Timestamp.new(Time.at(sec, nsec, :nsec).utc))
              tags = (event.get("tags") || []) << "ts_set"
              event.set("tags", tags.uniq)
            end
          end
        '
      }

      ruby {
        code => '
          unless (event.get("tags") || []).include?("ts_set")
            ["[raw_event][timestamp]", "[raw_event][time]", "[raw_event][datetime]", "[event][start]"].each do |p|
              v = event.get(p)
              if !v.nil? && v.to_s.strip != ""
                event.set("[@metadata][ts_raw]", v)
                break
              end
            end
          end
        '
      }

      if [@metadata][ts_raw] and !("ts_set" in [tags]) {
        date {
          match    => [ "[@metadata][ts_raw]", "ISO8601", "UNIX_MS", "YYYY-MM-dd HH:mm:ss.SSS" ]
          target   => "@timestamp"
          timezone => "UTC"
          tag_on_failure => ["date_parse_failed_coalesced"]
        }
        mutate { remove_field => "[@metadata][ts_raw]" }
      }

      if [raw_event][attributes] {
        ruby {
          code => '
            attrs = event.get("[raw_event][attributes]")
            merged = {}

            if attrs.is_a?(Array)
              attrs.each { |h| merged.merge!(h) if h.is_a?(Hash) }
            elsif attrs.is_a?(Hash)
              merged = attrs
            end

            unless merged.empty?
              event.set("[labels][otel_attributes]", merged)
              ev = event.get("event")
              ev = {} unless ev.is_a?(Hash)
              ev.merge!(merged)
              event.set("event", ev)
            end
          '
        }
      }

      if [raw_event] {
        ruby {
          code => '
            sdk_name  = event.get("[raw_event][resource][telemetry][sdk][name]")     || event.get("[raw_event][resource.telemetry.sdk.name]")
            sdk_ver   = event.get("[raw_event][resource][telemetry][sdk][version]")  || event.get("[raw_event][resource.telemetry.sdk.version]")
            sdk_lang  = event.get("[raw_event][resource][telemetry][sdk][language]") || event.get("[raw_event][resource.telemetry.sdk.language]")

            if sdk_name && (event.get("[agent][type]").nil? || event.get("[agent][type]").empty?)
              event.set("[agent][type]", sdk_name.to_s)
            end
            if sdk_ver && (event.get("[agent][version]").nil? || event.get("[agent][version]").empty?)
              event.set("[agent][version]", sdk_ver.to_s)
            end
            if sdk_lang && (event.get("[service][language][name]").nil? || event.get("[service][language][name]").empty?)
              event.set("[service][language][name]", sdk_lang.to_s)
            end
          '
        }

        mutate {
          rename => {
            "[raw_event][severity_text]" => "[log][level]"
            "[raw_event][severity_number]" => "[event][severity]"
            "[raw_event][body]"          => "message"
            "[raw_event][trace_id]"      => "[trace][id]"
            "[raw_event][span_id]"       => "[span][id]"

            "[raw_event][resource][project.name]"         => "[project][name]"
            "[raw_event][resource.project.name]"          => "[project][name]"

            "[raw_event][resource][service.name]"         => "[service][name]"
            "[raw_event][resource.service.name]"          => "[service][name]"
            "[raw_event][resource][service.version]"      => "[service][version]"
            "[raw_event][resource.service.version]"       => "[service][version]"
            "[raw_event][resource][service.namespace]"    => "[service][namespace]"
            "[raw_event][resource.service.namespace]"     => "[service][namespace]"
            "[raw_event][resource][service.instance.id]"  => "[service][id]"
            "[raw_event][resource.service.instance.id]"   => "[service][id]"

            "[raw_event][resource][deployment.environment]" => "[service][environment]"
            "[raw_event][resource.deployment.environment]"  => "[service][environment]"

            "[raw_event][resource][host.name]"            => "[host][name]"
            "[raw_event][resource][host.id]"              => "[host][id]"

            "[raw_event][resource][cloud.provider]"          => "[cloud][provider]"
            "[raw_event][resource][cloud.account.id]"        => "[cloud][account][id]"
            "[raw_event][resource][cloud.region]"            => "[cloud][region]"
            "[raw_event][resource][cloud.availability_zone]" => "[cloud][availability_zone]"

            "[raw_event][resource][k8s.namespace.name]"   => "[kubernetes][namespace]"
            "[raw_event][resource][k8s.pod.name]"         => "[kubernetes][pod][name]"
            "[raw_event][resource][k8s.container.name]"   => "[container][name]"

            "[event][event.provider]"    => "[service][name]"
            "[event][event.module]"      => "[event][module]"
            "[event][event.category]"    => "[event][category]"
            "[event][event.type]"        => "[event][type]"
            "[event][event.kind]"        => "[event][kind]"
            "[event][event.start]"       => "[event][start]"
            "[event][event.duration]"    => "[event][duration]"
            "[event][event.outcome]"     => "[event][outcome]"
            "[event][event.end]"         => "[event][end]"

            "[event][labels.environment]"         => "[labels][environment]"

            "[event][http.request.method]"        => "[http][request][method]"
            "[event][http.request.body.content]"  => "[http][request][body][content]"
            "[event][http.request.size]"          => "[http][request][bytes]"

            "[event][http.response.status_code]"  => "[http][response][status_code]"
            "[event][http.response.body.content]" => "[http][response][body][content]"
            "[event][http.response.size]"         => "[http][response][bytes]"

            "[event][url.full]"   => "[url][full]"
            "[event][url.scheme]" => "[url][scheme]"
            "[event][url.path]"   => "[url][path]"
            "[event][url.query]"  => "[url][query]"

            "[event][client.address]"      => "[client][address]"
            "[event][client.port]"         => "[client][port]"
            "[event][source.address]"      => "[source][address]"
            "[event][source.port]"         => "[source][port]"
            "[event][destination.address]" => "[destination][address]"
            "[event][destination.port]"    => "[destination][port]"

            "[event][user_agent.original]" => "[user_agent][original]"

            "[event][network.transport]"   => "[network][transport]"
            "[event][network.protocol]"    => "[network][protocol]"

            "[event][service.version]"     => "[service][version]"
            "[event][service.namespace]"   => "[service][namespace]"

            "[event][error.message]"       => "[error][message]"
            "[event][error.code]"          => "[error][code]"
            "[event][error.type]"          => "[error][type]"

            "[event][user.name]"           => "[user][name]"
            "[event][user.id]"             => "[user][id]"
          }
        }

        if ![event][outcome] and [http][response][status_code] {
          ruby {
            code => '
              status = event.get("[http][response][status_code]").to_i
              event.set("[event][outcome]", status >= 400 ? "failure" : "success")
            '
          }
        }

        if ![message] {
          if [raw_event][attr][message] {
            mutate { add_field => { "message" => "%{[raw_event][attr][message]}" } }
          } else if [raw_event][attr.message] {
            mutate { add_field => { "message" => "%{[raw_event][attr.message]}" } }
          } else if [raw_event][message] {
            mutate { rename => { "[raw_event][message]" => "message" } }
          }
        }

        if ![log][level] {
          if [raw_event][level] {
            mutate { add_field => { "[log][level]" => "%{[raw_event][level]}" } }
          } else if [raw_event][log_level] {
            mutate { add_field => { "[log][level]" => "%{[raw_event][log_level]}" } }
          }
        }
      }

      
      if ![raw_event] {
        if [raw_input][body] {
          mutate { add_field => { "message" => "%{[raw_input][body]}" "ecs_compatible" => "false" "[event][dataset]" => "fallback" } }
        } else if [raw_input][message] {
          mutate { add_field => { "message" => "%{[raw_input][message]}" "ecs_compatible" => "false" "[event][dataset]" => "fallback" } }
        } else {
          mutate { add_field => { "message" => "%{[raw_input]}" "ecs_compatible" => "false" "[event][dataset]" => "fallback" } }
        }
        mutate {
          rename => {
            "[raw_input][log_level]"                       => "[log][level]"
            "[raw_input][trace_id]"                        => "[trace][id]"
            "[raw_input][span_id]"                         => "[span][id]"

            "[raw_input][resource][project.name]"          => "[project][name]"
            "[raw_input][resource.project.name]"           => "[project][name]"

            "[raw_input][resource][service.name]"          => "[service][name]"
            "[raw_input][resource.service.name]"           => "[service][name]"
            "[raw_input][resource][service.version]"       => "[service][version]"
            "[raw_input][resource.service.version]"        => "[service][version]"
            "[raw_input][resource][service.namespace]"     => "[service][namespace]"
            "[raw_input][resource.service.namespace]"      => "[service][namespace]"
            "[raw_input][resource][service.instance.id]"   => "[service][id]"
            "[raw_input][resource.service.instance.id]"    => "[service][id]"

            "[raw_input][resource][deployment.environment]" => "[service][environment]"
            "[raw_input][resource.deployment.environment]"  => "[service][environment]"

            "[raw_input][resource][host.name]"            => "[host][name]"
            "[raw_input][resource][host.id]"              => "[host][id]"

            "[raw_input][resource][cloud.provider]"          => "[cloud][provider]"
            "[raw_input][resource][cloud.account.id]"        => "[cloud][account][id]"
            "[raw_input][resource][cloud.region]"            => "[cloud][region]"
            "[raw_input][resource][cloud.availability_zone]" => "[cloud][availability_zone]"

            "[raw_input][resource][k8s.namespace.name]"   => "[kubernetes][namespace]"
            "[raw_input][resource][k8s.pod.name]"         => "[kubernetes][pod][name]"
            "[raw_input][resource][k8s.container.name]"   => "[container][name]"
          }
          add_tag => ["non_opentelemetry", "non_ecs"]
        }
      }

      ruby {
        code => '
          proj = event.get("[project][name]") ||
                event.get("[raw_event][resource][project][name]") ||
                event.get("[raw_event][resource.project.name]") ||
                event.get("[raw_event][resource][application_name]") ||
                event.get("[raw_input][resource][application_name]")
          event.set("[project][name]", proj.to_s) if proj && !proj.to_s.empty?
        '
      }

    ruby {
        code => '
          def first_present(event, paths)
            paths.each do |p|
              v = event.get(p)
              return v unless v.nil? || (v.respond_to?(:empty?) && v.empty?)
            end
            nil
          end

          unless event.get("[@metadata][prj]")
            prj = first_present(event, [
              "[raw_event][resource][project][name]",
              "[raw_event][resource.project.name]",
              "[raw_event][project][name]",
              "[raw_event][project.name]",
              "[resource][project][name]",
              "[resource.project.name]",
              "[project][name]",
              "[fields][prj]"
            ])
            if prj
              event.set("[@metadata][prj]", prj.to_s)
            else
              event.set("[@metadata][prj]", "prj.unknown")
              event.tag("fallback_prj")
            end
          end

          unless event.get("[@metadata][srv]")
            srv = first_present(event, [
              "[raw_event][resource][service.name]",
              "[raw_event][resource.service.name]",
              "[raw_event][service][name]",
              "[resource][service.name]",
              "[resource.service.name]",
              "[service][name]",
              "[fields][srv]"
            ])
            if srv
              event.set("[@metadata][srv]", srv.to_s)
            else
              event.set("[@metadata][srv]", "srv.unknown")
              event.tag("fallback_srv")
            end
          end

          unless event.get("[@metadata][env]")
            env = first_present(event, [
              "[raw_event][resource][deployment][environment]",
              "[raw_event][resource][deployment.environment]",
              "[raw_event][resource.deployment.environment]",
              "[resource][deployment.environment]",
              "[resource.deployment.environment]",
              "[service][environment]",
              "[resource][env]",
              "[fields][env]"
            ])
            if env
              event.set("[@metadata][env]", env.to_s)
            else
              event.set("[@metadata][env]", "env.unknown")
              event.tag("fallback_env")
            end
          end
        '
      }

      mutate { lowercase => [ "[@metadata][prj]", "[@metadata][srv]", "[@metadata][env]" ] }

      ruby {
        code => '
          env = event.get("[@metadata][env]")
          if env && (event.get("[service][environment]").nil? || event.get("[service][environment]").to_s.empty?)
            event.set("[service][environment]", env.to_s)
          end
        '
      }

      ruby {
        code => '
          def slug(s)
            return nil if s.nil?
            x = s.to_s.downcase
            x = x.gsub(/[^a-z0-9_-]+/, "-").gsub(/^-+/, "").gsub(/-+$/, "")
            x.empty? ? nil : x
          end
          prj = slug(event.get("[@metadata][prj]"))
          srv = slug(event.get("[@metadata][srv]"))
          env = slug(event.get("[@metadata][env]"))
          if prj && env
            idx = (srv && srv != "srv-unknown") ? "logs-#{prj}-#{srv}-#{env}" : "logs-#{prj}-#{env}"
            event.set("[@metadata][target_index]", idx)
          end
          event.set("prj", prj) if prj
          event.set("srv", srv) if srv
          event.set("env", env) if env
        '
      }

      mutate {
        add_field => {
          "[observer][type]"    => "logstash"
          "[observer][vendor]"  => "Elastic"
          "[observer][product]" => "Logstash"
          "[observer][version]" => "8.17.0"
          "[input][type]"       => "tcp"
          "[labels][ingest_path]" => "logstash/tcp"
          "[labels][elk_index_prefix]" => "%{[@metadata][target_index]}"
        }
      }

      ruby {
        code => '
          require "time"
          idx = event.get("[@metadata][target_index]")
          ts  = event.get("@timestamp")
          if idx
            parts = idx.split("-")
            ds = parts.length >= 3 ? parts[0..-2].join("-") : idx
            event.set("[event][dataset]", ds)

            if ts
              begin
                t = ts.respond_to?(:time) ? ts.time.utc : Time.parse(ts.to_s).utc
                ymd = t.strftime("%Y.%m.%d")
                event.set("[labels][elk_index]", "#{idx}-#{ymd}")
              rescue
                tags = (event.get("tags") || []) << "date_format_error"
                event.set("tags", tags.uniq)
              end
            end
          end
        '
      }

      mutate { add_tag => ["via_logstash_tcp"] }

      mutate {
        rename => {
          "[event][http.request.headers]"        => "[http][request][headers]"
          "[event][http.response.headers]"       => "[http][response][headers]"
          "[raw_event][attributes][http.request.headers]"  => "[http][request][headers]"
          "[raw_event][attributes][http.response.headers]" => "[http][response][headers]"
        }
      }

      ruby {
        code => '
          def pick(event, *paths)
            paths.each do |p|
              v = event.get(p)
              return v if v
            end
            nil
          end

          def norm(h)
            return {} unless h.is_a?(Hash)
            out={}
            h.each{|k,v| out[k.to_s.downcase]=[v].flatten.compact.map(&:to_s).reject(&:empty?) }
            out
          end

          sensitive = [/^authorization$/i, /^proxy-authorization$/i, /^cookie$/i, /^set-cookie$/i, /token/i, /secret/i, /api[-_]?key/i]

          req = event.get("[http][request][headers]")  || {}
          res = event.get("[http][response][headers]") || {}
          req = norm(req); res = norm(res)

          attrs = pick(event, "[raw_event][attributes]", "[event]")
          if attrs.is_a?(Hash)
            attrs.each do |k,v|
              if k =~ /^http\.request\.header\.(.+)$/
                key = $1.to_s.downcase
                req[key] = [v].flatten.compact.map(&:to_s)
              elsif k =~ /^http\.response\.header\.(.+)$/
                key = $1.to_s.downcase
                res[key] = [v].flatten.compact.map(&:to_s)
              end
            end
          end

          [req,res].each do |h|
            h.keys.each do |k|
              if sensitive.any?{|pat| pat === k}
                h[k] = ["[REDACTED]"]
              else
                h[k] = h[k].uniq
              end
            end
          end

          event.set("[http][request][headers]", req)  unless req.empty?
          event.set("[http][response][headers]", res) unless res.empty?

          ua = (req["user-agent"] || []).first
          event.set("[user_agent][original]", ua) if ua && event.get("[user_agent][original]").nil?
        '
      }

      ruby {
        code => '
          ["[labels][otel_attributes][http.request.headers]",
           "[labels][otel_attributes][http.response.headers]"].each do |p|
            event.remove(p) if event.get(p)
          end
        '
      }

      mutate {
        convert => {
          "[http][response][status_code]" => "integer"
          "[http][request][bytes]"        => "integer"
          "[http][response][bytes]"       => "integer"
          "[client][port]"                => "integer"
          "[source][port]"                => "integer"
          "[destination][port]"           => "integer"
          "ecs_compatible"                => "boolean"
        }
      }
      
      ruby {
        code => '
          def first_present(event, paths)
            paths.each do |p|
              v = event.get(p)
              return v unless v.nil? || (v.respond_to?(:empty?) && v.empty?)
            end
            nil
          end

          if event.get("[log][level]").nil? || event.get("[log][level]").to_s.empty?
            candidate = first_present(event, [
              "[raw_event][severity_text]", "[raw_event][severityText]", "[raw_event][severity]",
              "[raw_event][level]", "[raw_event][log_level]", "[raw_event][logLevel]",
              "[raw_input][level]", "[raw_input][LEVEL]", "[raw_input][log_level]", "[raw_input][logLevel]",
              "[event][severity_text]", "[event][severityText]"
            ])
            event.set("[log][level]", candidate) if candidate
          end
        '
      }

      ruby {
        code => '
          v = event.get("[log][level]")
          n = nil
          if v.is_a?(Integer)
            n = v
          elsif v.is_a?(String) && v.strip =~ /^\d+$/
            n = v.to_i
          end

          # Se veio número, converte para ECS
          if n
            lvl = nil

            # .NET EventLevel (0..5)
            case n
            when 5 then lvl = "debug"      # Verbose
            when 4 then lvl = "info"       # Informational
            when 3 then lvl = "warning"    # Warning
            when 2 then lvl = "error"      # Error
            when 1 then lvl = "critical"   # Critical
            when 0 then lvl = "info"       # LogAlways -> info por padrão
            end

            # Syslog severities (10,20,...,60) caso alguém use escala 10x
            if lvl.nil?
              map_10x = {10=>"trace", 20=>"debug", 30=>"info", 40=>"warning", 50=>"error", 60=>"critical"}
              lvl = map_10x[n] if map_10x.key?(n)
            end

            # Log4j intLevel (10000..50000) e sobras
            if lvl.nil?
              lvl =
                if n >= 50000 then "emergency" # FATAL ~ 50000
                elsif n >= 40000 then "error"
                elsif n >= 30000 then "warning"
                elsif n >= 20000 then "info"
                elsif n >= 10000 then "debug"
                else "trace"
                end
            end

            event.set("[log][level]", lvl) if lvl
          end
        '
      }

      mutate { lowercase => [ "[log][level]" ] }

      translate {
        source => "[log][level]"
        target => "[log][level]"
        dictionary => {
          "inf"           => "info"
          "information"   => "info"
          "informational" => "info"
          "i"             => "info"
          "info"          => "info"
          "infolevel"     => "info"
          "3"             => "info"

          "warn"        => "warning"
          "w"           => "warning"
          "warnlevel"   => "warning"
          "5"           => "warning"
          "warning"     => "warning"

          "err"         => "error"
          "e"           => "error"
          "error"       => "error"
          "errorlevel"  => "error"
          "6"           => "error"

          "dbg"         => "debug"
          "d"           => "debug"
          "debug"       => "debug"
          "debuglevel"  => "debug"
          "2"           => "debug"

          "trc"         => "trace"
          "t"           => "trace"
          "trace"       => "trace"
          "tracelevel"  => "trace"
          "1"           => "trace"

          "crit"          => "critical"
          "c"             => "critical"
          "critical"      => "critical"
          "criticallevel" => "critical"
          "7"             => "critical"

          "a"      => "alert"
          "alert"  => "alert"
          "8"      => "alert"

          "emerg"        => "emergency"
          "emergency"    => "emergency"
          "fat"          => "emergency"
          "fatal"        => "emergency"
          "9"            => "emergency"

          "n"       => "notice"
          "notice"  => "notice"
          "4"       => "notice"
        }
        fallback => "%{[log][level]}"
      }

      if ("invalid_parse_json_otel_body" in [tags] or
          "invalid_parse_json_otel_original" in [tags] or
          "invalid_parse_json_generic_body" in [tags] or
          "invalid_parse_json_generic_message" in [tags] or
          "invalid_parse_json_generic_original" in [tags] or
          "fallback_prj" in [tags] or
          "fallback_srv" in [tags] or
          "fallback_env" in [tags]) {
        mutate { add_tag => ["pipeline_debug"] }
      }

      if !("pipeline_debug" in [tags]) { mutate { remove_field => "[event][original]" } }

      prune {
        interpolate => true
        whitelist_names => [
          "^@timestamp$", "^@version$", "^message$", "^tags$",
          # inclui server.* para manter após renames
          "^(event|log|host|project|service|ecs|trace|span|http|url|client|source|destination|server|user|user_agent|error|labels|network|agent|cloud|kubernetes|container|observer|input)(\.|$)",
          "^prj$", "^srv$", "^env$", "^uuid$",
          "^\[@metadata\]\[(prj|srv|env|target_index)\]$"
        ]
        blacklist_values => ["^$","^null$"]
      }

      uuid { target    => "uuid" overwrite => true }
      mutate { remove_field => ["raw_event", "raw_input"] }
      ruby { code => 'event.set("[event][ingested]", LogStash::Timestamp.now)'}
    }

    output {
      elasticsearch {
        hosts       => ["http://elastic-elkcorp-es-http:9200"]
        user        => "${ELASTIC_ELKCORP_ES_USER}"
        password    => "${ELASTIC_ELKCORP_ES_PASSWORD}"
        action      => "create"
        data_stream => false
        index       => "%{[@metadata][target_index]}-%{+YYYY.MM.dd}"
        document_id => "%{uuid}"
        ssl_enabled => false
      }
    }

# Reference a pipelines configuration in a Secret.
# ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-logstash-configuration.html#k8s-logstash-pipelines
#
# pipelinesRef:
#   secretName: ''

# volumeClaimTemplates
# ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-logstash-configuration.html#k8s-volume-claim-settings
#
volumeClaimTemplates:
    - metadata:
        name: logstash-data # Do not change this name unless you set up a volume mount for the data path.
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 100Gi
        storageClassName: default-ssd-storage-zrs

# ElasticsearchRefs are references to Elasticsearch clusters running in the same Kubernetes cluster.
# Ensure that the 'clusterName' field matches what is referenced in the pipeline.
# ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-logstash-configuration.html#k8s-logstash-pipelines-es
#
elasticsearchRefs:
  - clusterName: 'elastic-elkcorp' 
    namespace: 'eck-stack'
    name: 'elastic-elkcorp'
    #serviceName: 'elastic-sla-es-master'

# services:
#    - name: beats
#      service:
#       spec:
#         ports:
#         - port: 5044
#           name: "filebeat"
#           protocol: TCP

services:
   - name: beats
     service:
      spec:
        ports:
        - port: 5044
          name: "tcp-logstash-beats"
          protocol: TCP
        - port: 5045
          name: "tcp-logstash-secure"
          protocol: TCP
        - port: 5080
          name: "tcp-logstash-standard"
          protocol: TCP

# SecureSettings is a list of references to Kubernetes Secrets containing sensitive configuration options for the Logstash
secureSettings: []